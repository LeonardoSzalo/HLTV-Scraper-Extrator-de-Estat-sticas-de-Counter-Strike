# HLTV Scraper: Extrator de EstatÃ­sticas de Counter-Strike
Um web scraper construÃ­do com Scrapy e Selenium para extrair dados detalhados de jogadores e resultados de partidas do HLTV.org, o principal portal de notÃ­cias e estatÃ­sticas de Counter-Strike.

## ğŸ“– Sobre o Projeto
Este projeto foi desenvolvido para automatizar a coleta de dados estatÃ­sticos de times profissionais de Counter-Strike. A ferramenta navega pelo site da HLTV, contornando proteÃ§Ãµes de anti-bot como Cloudflare e pop-ups de consentimento de cookies, para extrair informaÃ§Ãµes valiosas e estruturÃ¡-las em arquivos CSV para fÃ¡cil anÃ¡lise.

O scraper Ã© capaz de coletar:

EstatÃ­sticas Gerais dos Jogadores: K/D Ratio, Rating 2.0, Mapas Jogados, etc.

EstatÃ­sticas por Lado: Desempenho dos jogadores atuando como Terrorista (TR) e Contra-Terrorista (CT).

Resultados de Partidas: HistÃ³rico de confrontos dos times, incluindo oponentes, placares e mapas.

## âœ¨ Funcionalidades Principais
Scraping dos Top 50 Times: Automaticamente coleta dados dos times mais bem ranqueados em um perÃ­odo prÃ©-definido.

ManipulaÃ§Ã£o de ConteÃºdo DinÃ¢mico: Utiliza Selenium com undetected-chromedriver para renderizar pÃ¡ginas baseadas em JavaScript e interagir com elementos da pÃ¡gina (ex: aceitar cookies).

Dados Estruturados: Salva os dados coletados em quatro arquivos CSV distintos para uma anÃ¡lise organizada:

hltv_all_player_stats.csv (EstatÃ­sticas gerais)

hltv_terrorist_stats.csv (EstatÃ­sticas como Terrorista)

hltv_ct_stats.csv (EstatÃ­sticas como Contra-Terrorista)

hltv_match_results.csv (Resultados de partidas)

Scraping Consciente: Implementa delays e a extensÃ£o AutoThrottle do Scrapy para interagir com o site de forma respeitosa, evitando sobrecarregar seus servidores.

## ğŸ› ï¸ Tecnologias Envolvidas
Este projeto utiliza uma combinaÃ§Ã£o de tecnologias poderosas para web scraping e manipulaÃ§Ã£o de dados:

Python: Linguagem de programaÃ§Ã£o principal.

Scrapy: Framework de web crawling para a estrutura geral do scraper, gerenciamento de requisiÃ§Ãµes e processamento de dados.

Selenium: Ferramenta de automaÃ§Ã£o de navegador para lidar com JavaScript, interaÃ§Ãµes e conteÃºdo dinÃ¢mico.

Undetected Chromedriver: VersÃ£o otimizada do Chromedriver para evitar detecÃ§Ã£o por sistemas anti-bot.

Pandas: Biblioteca utilizada para processar os dados coletados e exportÃ¡-los para arquivos CSV.

## ğŸš€ ComeÃ§ando
Siga estas instruÃ§Ãµes para configurar e executar o projeto em sua mÃ¡quina local.

### PrÃ©-requisitos
Antes de comeÃ§ar, garanta que vocÃª tenha os seguintes softwares instalados:

Python 3.8 ou superior

pip (gerenciador de pacotes do Python)

Google Chrome (instalado em sua versÃ£o mais recente)

Git

### InstalaÃ§Ã£o e Uso
Clone o repositÃ³rio:
```
git clone https://github.com/seu-usuario/hltv-scraper.git
cd hltv-scraper
```


### Crie e ative um ambiente virtual (recomendado):

No Windows:
```
python -m venv venv
.\venv\Scripts\activate
```
No macOS/Linux:
```
python3 -m venv venv
source venv/bin/activate
```
### Instale as dependÃªncias:
```
pip install -r requirements.txt
```

### Configure o Chromedriver:

Baixe o Chromedriver: FaÃ§a o download da versÃ£o do Chromedriver que corresponda exatamente Ã  versÃ£o do seu Google Chrome. VocÃª pode encontrÃ¡-lo no site oficial do Chrome for Testing.

Atualize o caminho: Extraia o arquivo chromedriver.exe (ou chromedriver em macOS/Linux) para uma pasta de sua preferÃªncia. Abra o arquivo hltv_scraper/settings.py e atualize a variÃ¡vel UNDETECTED_CHROMEDRIVER_PATH com o caminho completo para o executÃ¡vel.

Exemplo em settings.py:

## Altere este caminho para o local onde vocÃª salvou o chromedriver
UNDETECTED_CHROMEDRIVER_PATH = "C:/caminho/completo/para/drivers/chromedriver.exe"

## Execute o Scraper:
Com tudo configurado, execute o scraper a partir do diretÃ³rio raiz do projeto com o seguinte comando:

scrapy crawl hltv_spider

O processo serÃ¡ iniciado, e vocÃª verÃ¡ os logs da execuÃ§Ã£o no seu terminal. Ao final, os arquivos CSV serÃ£o gerados na raiz do projeto.
```
ğŸ“ Estrutura do Projeto
hltv-scraper/
â”‚
â”œâ”€â”€ hltv_scraper/
â”‚   â”œâ”€â”€ spiders/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ hltv_spider.py       # LÃ³gica principal do spider (requests e parsing)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ items.py                 # DefiniÃ§Ã£o dos itens de dados (data containers)
â”‚   â”œâ”€â”€ middlewares.py           # Middleware com Selenium para processar requests
â”‚   â”œâ”€â”€ pipelines.py             # Pipeline para processar e salvar os itens em CSV
â”‚   â””â”€â”€ settings.py              # ConfiguraÃ§Ãµes do projeto (delays, paths, etc.)
â”‚
â””â”€â”€ scrapy.cfg                   # Arquivo de configuraÃ§Ã£o de deploy do Scrapy
```
ğŸ“„ SaÃ­da
ApÃ³s a execuÃ§Ã£o bem-sucedida, quatro arquivos CSV serÃ£o criados no diretÃ³rio raiz do projeto, contendo os dados estruturados:

hltv_all_player_stats.csv: EstatÃ­sticas gerais de cada jogador.

hltv_terrorist_stats.csv: EstatÃ­sticas de cada jogador no lado Terrorista.

hltv_ct_stats.csv: EstatÃ­sticas de cada jogador no lado Contra-Terrorista.

hltv_match_results.csv: HistÃ³rico detalhado das partidas do time.

âš–ï¸ LicenÃ§a
DistribuÃ­do sob a LicenÃ§a MIT. Veja LICENSE.txt para mais informaÃ§Ãµes.
